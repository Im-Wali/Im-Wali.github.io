---
title:  "[AI] : 01. AI 역사와 발전 과정"
search: false
categories:
  - AI
  - ML
tags:
  - AI
  - ML
  - Machine Learning
  - Supervised
  - Unsupervised
  - Semi-Supervised
  - Reinforcement Learning 
  - 지도학습
  - 비지도학습
  - 준지도학습
  - 강화학습

---
<br/>

## 서론
  * 이번 포스팅에서는 기계학습(ML : Machine Learning)에 대해서 알아 보도록 하겠다. 이전 포스팅에서 간단하게 얘기하였지만, ML에 대한 설명과 학습 방법에 따른 구분에 따른 특징을 조금더 상세하게 다룰 예정이다.

## 01. 기계학습
### 1) 기계학습이란?
  * 기계학습(ML : Machine Learning)은 AI의 한 분야로써, 학습을 통해 데이터를 분석하여 데이터의 패턴 혹은 특징을 인식하여 예측 모델을 만드는 기술이다. 학습 데이터로 데이터 특성을 학습하였다면 새로운 데이터를 입력 받으면 이를 분류/예측 해주는 기술이다. 대표적으로 Decision Tree, Regression, SVM 등이 있다. 
  <br/>

### 2) 기계학습의 주요 구성 요소 
  * 기계학습을 주요 구성 요소는 데이터, 모델, 학습 알고리즘, Feature, 훈련으로 나눌수 있다. 
  <br/>

  * **데이터(Data)** : 학습을 위해서 사용되는 데이터로써 특정 문제에 대한 데이터 이다(예 : 고양이, 강아지 분류 문제에서 고양이, 강아지 사진). 훈련 데이터 형태에 따라서 훈련 방식이 달라진다.
  <br/>

  * **모델(Model)** : 데이터를 기반으로 패턴을 학습하는 알고리즘이라고 생각하면 된다. 문제에 따라서 최적화된 모델이 있다. 
  <br/>

  * **피처(Feature)** : 데이터에 대한 특징을 말한다. 실제 학습은 각 데이터의 특징(Feature)를 학습을 하는것이다. 학습을 통해서 특징을 알아내고 이를 통해서 문제를 해결한다.
  <br/>


  * **훈련(Training)** : 데이터를 학습하는 과정을 말하며, 훈련은 훈련 목적에 의해 데이터를 나눈다. 예를 들면 초기 학습을 위한 데이터를 훈련(Training) 데이터라고 하며 중간에 검증(Validation) 데이터라고 한다. 그리고 마지막에 성능을 테스트하기 위한 데이터를 테스트(Test) 데이터라고 한다.
  <br/>


### 3) 학습 방법에 따른 구분 
  * 학습 방법에 따라서 부르는 방식이 다르다. 특히 정답(Label)이 있는 데이터를 사용하는지 여부에 따라서 구분하는데, 지도학습, 비지도학습, 준지도 학습, 강화학습으로 구분할 수 있다.
  <br/>

  * 무조건 한 학습 방법이 좋은것이 아니라 문제에 따라 혹은 데이터 형태에 따라서 각 학습 방법을 선택하여 사용하는것이 좋다.
  <br/>

  ![image-center](/assets/images/2024-07-08-ML_BASIC_01.jpg){: .align-center width="100%" height="100%"}
  <div style="text-align: right"> [참고: https://wendys.tistory.com/169] </div>
  <br/>
  <br/>


## 02. 지도학습
### 1) 지도학습(Supervised Learning)
  * 지도 학습은 말 그대로 학습을 지도하는 방식으로, 데이터가 정답(Label)과 입력(Input)이 한쌍으로 되어 있다. 모델을 학습할때 정답을 정확하게 전달 함을써 학습을 정확하고 쉽게(빠르게) 진행할 수 있다. 예를 들면 꽃 분류 문제를 학습한다면 해당 꽃 사진과 꽃 명칭(정답)을 함께 전달하는 방식으로 학습을 진행한다.
  <br/>

  * 지도 학습이 제일 많이 활용 되는 문제는 회귀(Regression)과 분류(Classification) 문제가 있다.
  <br/>

### 2) 지도학습이 적합한 문제
#### 회귀(Regression)
  - Regression은 출력에 대한 연속적인 값(실수)를 가지는데, 주어진 입력과 출력(정답)이 대응되는 연속 함수를 찾는 문제이다. 분류 보다 난이도가 높으며 실수로 나타내는 값을 찾아가는 과정이 힘들다. 예를 들면 주택 가격 예측, 주식 시장 예측을 들수 있다.
  <br/>

#### 분류(Classification)
  - Classification은 미리 정의된 클래스 중 하나를 예측하는 문제이다. 학습 난이도가 제일 낮은 문제 중에 하나이며, 미리 정의된 클래스가 있기 때문에 딱 구분된다. 예를 들면 이메일 스팸 필터링, 이미지 객체 인식 등이 있다.
  <br/>

  ![image-center](/assets/images/2024-07-08-ML_BASIC_02.jpg){: .align-center width="100%" height="100%"}
  <div style="text-align: right"> [참고: https://wendys.tistory.com/169] </div>
  <br/>

### 3) 장점
  - **정확도가 높음** : 학습 데이터를 정답과 같이 제공하기 때문에 정확도가 높다.
  <br/>

  - **모든 문제에 적용 가능** : 정답을 매핑할 수 있는 문제라면 어떠한 문제라도 적용이 가능하여 다양한 분야에 적용이 가능하다. 
  <br/>

  - **해석 가능** : 지도학습의 경우 데이터를 대한 라벨링이 확실하기 때문에 다른 학습 방법에 비해서 해석이 가능하다. 다만 지도학습 또한 모든 문제를 완벽하게 해석 가능하지는 않다.
  <br/>

### 4) 단점 
  - **데이터 의존성** : 지도 학습이 효과적으로 학습하기 위해서는 양질의 많은 데이터가 필요하다. 아무리 데이터가 라벨링이 되어 있어도 적은 데이터로는 좋은 성능을 얻을 수 없다. 
  <br/>

  - **과적합 가능성 높음** : 훈련 데이터가 정확하게 정답이 달려 있기 때문에 과적합에 취약하다. 이를 방지하기 위해서 교차 검증 등 다른 방법을 사용하여야 한다. 
  <br/> 

  - **레이블링 비용** : 지도 학습을 위해서는 데이터의 레이블링이 되어 있어야 한다. 하지만 이 부분 또한 비용으로 연결된다. 특히 전문 분야 일 수록 고급인력이 레이블링을 해야되기 때문에 시간과 비용이 많이 든다는 단점이 있다. 
  <br/>
  <br/>



## 03. 비지도학습
### 1) 비지도학습(unsupervised Learning)
  * 비지도 학습은 지도학습과 반대로 학습 데이터의 레이블이 없는 형태이다. 학습 데이터의 정답이 없이 입력만으로 이뤄져 있기 때문에 입력의 대한 패턴과 입력간 상관 관계를 학습하는 것을 목적을 한다.
  <br/>

  * 지도 학습 보다는 난이도가 높지만, 레이블링 비용이 추가로 발생하지 않기 때문에 비용적인 측면에서는 지도 학습보다 우위에 있다. 대표적인 방법으로는 Clsutering과 Feture Extraction이 있다.
  <br/>

### 2) 비지도학습이 적합한 문제
#### 군집(Clustering)
  * Clustering은 비슷한 특징을 가진 데이터을 묶어 데이터를 분류하는 알고리즘으로 Feature가 표현된 공간에서 거리를 사용하여 밀집된 형태로 군집을 보여준다. 예를 들면 고객 세분화, 문서 분류 등이 있다. Clustering에서 많이 사용하는 알고리즘은 K-Means, DBSCAN 등이 있다.
  <br/>

  ![image-center](/assets/images/2024-07-08-ML_BASIC_03.jpg){: .align-center width="100%" height="100%"}
  <div style="text-align: right"> [참고: https://alasheep.com/blog/2020/07/02/ml-classification/] </div>
  <br/>


#### 차원 축소(Dimensionality Reduction)
  * 차원 축소는 고차원의 데이터를 저차원으로 변환하는 방법으로 데이터의 특징을 유지하면서 단순화 하는것을 목표로 한다. 데이터 시각화나 노이즈 제거등으로 사용된다. 많이 사용되는 알고리즘으로는 PCA가 있다.
  <br/>
  ![image-center](/assets/images/2024-07-08-ML_BASIC_04.jpg){: .align-center width="60%" height="100%"}

  ![image-center](/assets/images/2024-07-08-ML_BASIC_05.jpg){: .align-center width="60%" height="100%"}
  <div style="text-align: right"> [참고: https://codingalzi.github.io/handson-ml3/dimensionality_reduction.html] </div>
  <br/>

### 3) 장점
  - **레이블링 비용이 없음** : 비지도 학습 특징 상 레이블링 작업이 필요 없기 때문에 레이블링 비용을 절약할 수 있다. 
  <br/>

  - **데이터 확보 용이** : 레이블링이 필요 없기 때문에 지도학습에 비해서 학습 데이터를 확보하기 용이하다. 데이터를 많이 확보하면 정확도를 올릴 수 있기 때문에 중요하다.
  <br/>


### 4) 단점 
  - **결과 해석이 어려움** : 지도 학습의 경우 레이블링을 사람이 직접하기 때문에 결과를 해석하는것이 상대적으로 쉬운 반면, 비지도학습은 결과를 해석하기 힘들다는 단점이 있다.
  <br/>

  - **정확도 낮음** : 지도 학습의 경우 정답이 확실하기 때문에 정확도가 높은 반면, 비지도 학습의 경우는 정답을 판단하기 애매하고 또한 정확도도 지도학습에 비해서 낮다.
  <br/>
  <br/>

## 04. 준지도 학습
### 1) 준지도 학습(Semi-Supervised Learning)
  * 정답이 있는 데이터(Labeled Data)와 정답이 없는 데이터(Unlabeled Data)를 함꼐 학습 데이터로 사용하는 방법으로, 지도학습 시 Labeled Data가 부족할 때 보완하기 위한 방법이다. 일부 Labeled Data를 통해서 정확도를 높이는걸 목표로 한다.
  <br/>

### 2) 준지도 학습 알고리즘
#### Pseudo-Labeling
  *  초기에 예측된 결과를 통해서 라벨링하고 이 라벨링을 실제 라벨로 취급하여 모델을 학습시키는 방법.
  <br/>

  ![image-center](/assets/images/2024-07-08-ML_BASIC_06.jpg){: .align-center width="100%" height="100%"}
  <div style="text-align: right"> [참고: https://www.analyticsvidhya.com/blog/2017/09/pseudo-labelling-semi-supervised-learning-technique/] </div>
  <br/>



### 3) 장점
  - **레이블링 비용 절감** : 소량의 레이블링 데이터만 필요하기 때문에 레이블링 비용을 절감할 수 있다.
  <br/>

  - **성능 향상** : Unlabeled Data만 사용했을때 보다 보다 좋은 성능을 가질 가능성이 크다.
  <br/>


### 4) 단점 
  - **복잡성 증가** : Labeled Data와 Unlabeled Data 두가지 종류의 데이터를 사용하기 때문에 복잡성이 증가한다.
  <br/>

  - **불확실성** : 라벨이 없는 데이터를 학습하는 과정에서 잘못된 예측이 모델에 영향을 미칠 수 있다. 
  <br/>
  <br/>


## 05. 강화 학습
### 1) 강화 학습(Reinforcement learning)
  * 주어진 환경에서 최대 보상을 주는 방향으로 학습하는 방법이다. 행동의 주체자(Agent)는 행동(Action)에 대한 보상을 얻어서, 같은 행동을 해도 주체자가 얻는 봉상은 환경에 현재 상태(sate)에 따라서 다를 수 있다. 예를 들어 게임 이론이나 자율 주행 등을 들수 있다.
  <br/>

  ![image-center](/assets/images/2024-07-08-ML_BASIC_07.jpg){: .align-center width="100%" height="100%"}
  <div style="text-align: right"> [참고: https://youtu.be/BPCAP7DHLYw?t= 17] </div>
  <br/>

### 2) 강화 학습 알고리즘
#### Q-Learning
  *  상태-행동 쌍에 대한 Q값(행동 가치)을 학습하는 방법으로 Q-Learning은 정책을 명시적으로 학습하지 않고 Q값을 통해서 최적을 암시적으로 학습한다. 
  <br/>

#### SARSA(State-Action-Reward-State-Action)
  *  현재 정책에 따라서 행동을 선택하여 Q값(행동 가치)를 업데이트하는 방법으로 Q-Learning과 다르게 SARSA는 정책을 직접적으로 반영한다. 
  <br/>

### 3) 장점
  - **적응력** : 강화 학습은 실제 환경에 행동을 배울수 있어서 실제적인 문제 해결에 적용할 수 있다는 장점이 있다.
  <br/>

  - **높은 성능** : 복잡한 문제에 대해서 인간 이상의 성능을 보일 수 있다. 예를 들면 알파고를 들수 있다.
  <br/>


### 4) 단점 
  - **복잡성 증가** : 알고리즘의 구현이 복잡하다.
  <br/>

  - **학습 시간** : 학습할때 환경, 행동 등 감안할것이 많아서 학습시간이 많이 든다.
  <br/>
  <br/>

## 06. 끝마치며
  * 이번 포스팅에서는 각 학습 방법에 따른 자세한 설명을 했다. 다음 시간부터는 각 학습 방법에서 소개했던 알고리즘을 대해서 다루도록 하겠다.
